{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDN with Learnable parameters\n",
    "\n",
    "In this tutorial, we extends DDN Robust Pooling to the training of $\\alpha$ parameter, recall from the paper, authors computed the gradient of robust pooling respect to input x. The $\\alpha$ parameter is fixed during proprogation, thus there is no need compute the gradient respect to parameter $\\alpha$. Now we relax this restriction, include $\\alpha$ as a trainable parameter and compute its derivate.\n",
    "\n",
    "In general,the compuation of $Dy(\\alpha)$ is the same as $Dy(x)$: pervious we compute $D^2_{XY}f(x,y), D^2_{YY}f(x,y), D_{X}h(x,y) , D^2_{XY}h(x,y), D^2_{YY}f(x,y)$, now we change every x to $\\alpha$: That is $D^2_{\\alpha Y}f(\\alpha,y), D^2_{YY}f\\alpha,y), D_{\\alpha}h(\\alpha,y) , D^2_{\\alpha Y}h(\\alpha,y), D^2_{YY}f(\\alpha,y). $ Note we write $f(\\alpha,x,y )$ as $f(\\alpha ,y)$ because x can be treated as a constant for $Dy(\\alpha)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closed-form Gradient  for robust pooling\n",
    "In this section we compute the closed-form gradient of 4 different robust pooling function: peseudo-huber, huber, welsch and truncated quadratic.\n",
    "\n",
    "Recall the gradient for unconstrained function: $D(y(\\alpha)) = -H^{-1}B$ where $H= D^2_{YY}f(\\alpha, y)$ and $B= D^2_{\\alpha Y} f(\\alpha,y) $\n",
    "\n",
    "### Pseudo- Huber\n",
    "\n",
    "$y \\in  \\text{argmin}_y  \\sum_i^n \\alpha^2 (\\sqrt {1+ \\frac {(y-x_i)^2} {\\alpha^2}}-1)$\n",
    "\n",
    "\n",
    "$Dy(\\alpha) = -\\sum_{i=1}^N \\sum_{j=1}^N((\\frac {y-x_i} {\\alpha})^2 + 1)^{\\frac{3}{2}}(\\frac {(y-x_j)^3} {((\\frac {y-x_j} {\\alpha})^2 + 1)^{\\frac{3}{2}}\\alpha^3})$\n",
    "\n",
    "###  Huber\n",
    "\n",
    "$y \\in \\text{argmin}_y \\sum_{i=1}^N $ $\\begin{cases} \n",
    "\\frac {1} {2} (y-x_i)^2 & \\text{$ |y-x_i| \\leq \\alpha $} \\\\\n",
    "\\alpha(|y-x_i|-\\frac {1} {2} \\alpha) & \\text{otherwise}\\\\\n",
    "\\end{cases}$\n",
    "\n",
    "$Dy(\\alpha) = \\sum_{i=1}^N $ $\\begin{cases} \n",
    "0 & \\text{$ |y-x_i| \\leq \\alpha $} \\\\\n",
    "1 & \\text{$ y - x_i > \\alpha $}\\\\\n",
    "-1 & \\text{$ y - x_i < \\alpha $}\n",
    "\\end{cases}$\n",
    "\n",
    "### Welsch\n",
    "\n",
    "$y \\in  \\text{argmin}_y  \\sum_{i=1}^n (1-exp(- \\frac {(y-x_i)^2} {2\\alpha^2}))$\n",
    "\n",
    "$Dy(\\alpha) = \\sum_{i=1}^N (- \\frac {e^{-\\frac {(y-x_i)^2} {2 \\alpha^2}} (2 (y-x_i) \\alpha^2 - (y-x_i)^3)} {\\alpha^5}) $\n",
    "\n",
    "### Truncated Quadatic\n",
    "\n",
    "$y \\in \\text{argmin}_y \\sum_{i=1}^N $ $\\begin{cases} \n",
    "\\frac {1} {2} (y-x_i)^2 & \\text{$ |y-x_i| \\leq \\alpha $} \\\\\n",
    "\\frac {1} {2} \\alpha^2 & \\text{otherwise}\\\\\n",
    "\\end{cases}$\n",
    "\n",
    "$Dy(\\alpha) = 0$\n",
    "\n",
    "###  Implementation\n",
    "\n",
    "Below is the implmentation of $Dy(\\alpha)$, I adapted some previous code from DDN repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import autograd.numpy as np\n",
    "import scipy.optimize as opt\n",
    "import scipy as sci\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from autograd import grad, jacobian\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"../\")\n",
    "from ddn.basic.learnable_robust_nodes import LearnableRobustAverage\n",
    "from ddn.basic.learnable_robust_nodes_new import LearnableRobustAverageNew\n",
    "from ddn.basic.robust_nodes import RobustAverage\n",
    "#from ddn.pytorch.learnable_projections import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dyalpha_closed_form(x,y,alpha,p='pseudo-huber'):\n",
    "    alpha_sq=alpha**2\n",
    "    if p=='pseudo-huber':\n",
    "        dyy = np.array([np.power(1.0 + np.power(y - xi, 2.0) / alpha_sq, -1.5) for xi in x])\n",
    "        dytheta =  np.sum([np.power(y-xi,3)/(np.power(np.power((y-xi)/alpha,2)+1,1.5)*np.power(alpha,3)) for xi in x])\n",
    "    elif p=='huber':\n",
    "        dyy = np.array([1.0 if np.abs(y - xi) <= alpha else 0.0 for xi in x])\n",
    "        dytheta = np.sum(np.array([0.0 if np.abs(y - xi) <= alpha else (1.0 if y-xi>0 else -1.0) for xi in x]))\n",
    "    elif p=='welsch':\n",
    "        z = np.power(x - y, 2.0)\n",
    "        dyy = np.array([(alpha_sq - zi) / (alpha_sq * alpha_sq) * np.exp(-0.5 * zi / alpha_sq) for zi in z])\n",
    "        dytheta=np.sum(np.array([-np.exp(-0.5 * np.power((y - xi)/alpha,2))*((2*(y-xi)*alpha_sq-np.power(y-xi,3))/(alpha**5)) for xi in x])) \n",
    "    elif p=='trunc-quad':\n",
    "        return 0\n",
    "    return -1.0 * dytheta/np.sum(dyy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the gradient using pytorch autograd libray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dyalpha(x,y,alpha,p='pseudo-huber'):\n",
    "    fY = grad(f, 1)\n",
    "    #print(\"fy\",fY(x, y, alpha,p))\n",
    "    fYY = jacobian(fY, 1)\n",
    "    fthetaY = jacobian(fY, 2)\n",
    "    return -1.0 * np.linalg.pinv(fYY(x, y, alpha,p)).dot(fthetaY(x, y, alpha,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the correctness of closed form graident by comparing it with autograd gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the objective function from ddn.basic.node\n",
    "def f(x, y, alpha,p='pseudo-huber'):\n",
    "    alpha_sq=alpha**2\n",
    "    if p=='pseudo-huber':\n",
    "        phi= lambda z: (alpha**2) * (np.sqrt(1.0 + np.power(z, 2.0) / (alpha**2)) - 1.0)\n",
    "    elif p=='huber':\n",
    "        phi = lambda z: np.where(np.abs(z) <= alpha, 0.5 * np.power(z, 2.0), alpha * np.abs(z) - 0.5 * alpha_sq)\n",
    "    elif p=='welsch':\n",
    "        phi = lambda z: 1.0 - np.exp(-0.5 * np.power(z, 2.0) / alpha_sq)\n",
    "    elif p=='trunc-quad':\n",
    "        phi = lambda z: np.minimum(0.5 * np.power(z, 2.0), 0.5 * alpha_sq)\n",
    "    return np.sum([phi(y - xi) for xi in x])\n",
    "\n",
    "# the solve objective function from ddn.basic.node\n",
    "def solve(x,alpha ,f, p='pseudo-huber'):\n",
    "    result = opt.minimize(lambda y : f(x, y, alpha,p), np.mean(x))\n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 10 # number of input points\n",
    "y_target = np.array([0.0])\n",
    "x_init = np.random.rand(n)\n",
    "# add an outlier\n",
    "x_init[np.random.randint(len(x_init))] += 100.0 * np.random.rand(1)\n",
    "x_init=np.array([ 1.4748, -0.0034,  2.1072, -0.0675, -0.7821, -0.9080, -2.0427,\n",
    "          -1.9460,  1.7862,  0.1601])\n",
    "alpha_init = random.uniform(0.1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [ 1.4748 -0.0034  2.1072 -0.0675 -0.7821 -0.908  -2.0427 -1.946   1.7862\n",
      "  0.1601]\n",
      "alpha: 3.323251798608022\n",
      "[-0.02214]\n",
      "6.251444836489072\n",
      "[0.00510681]\n",
      "0.005106805731382436\n"
     ]
    }
   ],
   "source": [
    "print('x:',x_init)\n",
    "print('alpha:',alpha_init)\n",
    "print(np.array([np.mean(x_init)]))\n",
    "print(f(x_init,np.array([np.mean(x_init)]),1.0))\n",
    "print(dyalpha(x_init,np.array([np.mean(x_init)]),alpha_init,'pseudo-huber'))\n",
    "print(dyalpha_closed_form(x_init,np.array([np.mean(x_init)]),alpha_init,'pseudo-huber'))\n",
    "# valid the analyic gradient is the same as autograd solution\n",
    "#print(\"error between autograd and closed-form:\")\n",
    "#y_init = solve(x_init,alpha_init,f,'pseudo-huber')\n",
    "#print(\"pseudo-huber \",abs(dyalpha_closed_form(x_init,y_init,alpha_init,'pseudo-huber')-dyalpha(x_init,y_init,alpha_init,'pseudo-huber')))\n",
    "#y_init = solve(x_init,alpha_init,f,'huber')\n",
    "#print(\"huber \",abs(dyalpha_closed_form(x_init,y_init,alpha_init,'huber')-dyalpha(x_init,y_init,alpha_init,'huber')))\n",
    "#y_init = solve(x_init,alpha_init,f,'welsch')\n",
    "#print(\"welsch \",abs(dyalpha_closed_form(x_init,y_init,alpha_init,'welsch')-dyalpha(x_init,y_init,alpha_init,'welsch')))\n",
    "#y_init = solve(x_init,alpha_init,f,'trunc-quad')\n",
    "#print(\"trunc-quad\",abs(dyalpha_closed_form(x_init,y_init,alpha_init,'trunc-quad')-dyalpha(x_init,y_init,alpha_init,'trunc-quad')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closed-form Gradient  for ball projection\n",
    "Similar to robust pooling, we can compute the gradient respect to ball projection. \n",
    "\n",
    "Recall the gradient for equal constrained function:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "    &Dy(r) = (H^{-1} A^T(AH^{-1}A^T)^{-1}AH^{-1}B-C)-H^{-1}B\\\\\n",
    "    &A = D_Y h(x,y, r)\\\\\n",
    "    &B = D^2_{rY} f(x,y, r) - \\sum_{i=1}^pD^2_{rY} h_i(x,y, r)\\\\\n",
    "    &C= D_r h(x,y, r)\\\\\n",
    "    &H= D^2_{YY} f(x,y, r) - \\sum_{i=1}^pD^2_{YY} h_i(x,y, r)\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The ball projection problem in general is defined:\n",
    "\n",
    "\\begin{array}{lll}\n",
    "    y \\in & \\text{argmin}_u & \\frac{1}{2} \\|u - x\\|^2_2 \\\\\n",
    "    & \\text{subject to} & \\|x\\|_p = r \\\\\n",
    "\\end{array}\n",
    "\n",
    "### 1. analyical gradient using DDN theorm with equality constraint.\n",
    "### L2 norm:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "    y \\in & \\text{argmin}_u & \\frac{1}{2} \\|u - x\\|^2 \\\\\n",
    "    & \\text{subject to} & u_1^2 + u_2^2 - r^2 = 0 \\\\\n",
    "    & & \n",
    "\\end{array}\n",
    "\\begin{array}{lll}\n",
    "    y \\in & \\text{argmin}_u & \\frac{1}{2} \\|u - x\\|^2 \\\\\n",
    "    & \\text{subject to} & u_1^2 + u_2^2 - r^2 = 0 \\\\\n",
    "    & & \n",
    "\\end{array}\n",
    "$$\n",
    "#### (a) analyical gradient using DDN theorm with equality constraint.\n",
    "$$\n",
    "\\begin{array}{llll}\n",
    "    A = \\text{D}_{Y} h(r,y) &= 2 u^T \\\\\n",
    "    B = \\text{D}^2_{rY} f(r, y) - \\sum_{i=1}^{3} \\lambda_i \\text{D}^2_{rY} h_i(r,y) &=0 \\\\\n",
    "    C = \\text{D}_{Y} h(r,y) &= -2r\\\\\n",
    "    2u^T \\lambda= u^T -x^T \\Rightarrow \\lambda= \\sqrt{\\frac {(u^T-x^T)(u-x)} {4^T}}\\\\ \n",
    "    H = \\text{D}^2_{YY} f(r, y) - \\sum_{i=1}^{3} \\lambda_i \\text{D}^2_{YY} h_i(r,y) &= (1 - 2 \\lambda_1) I \\\\\n",
    "    Dy(r) =  r \\cdot \\frac {y} {y^T y}\n",
    "\\end{array}\n",
    "$$\n",
    "#### (b)analyical gradient of closed form\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "    y(x,r) = \\frac {r} {\\| x\\|_2} x\\\\\n",
    "    Dy(r) = \\frac {1} {\\| x\\|_2} x\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "#### (c)gradient using DDN theorm with autograd.\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "    Dy(r) = (H^{-1} A^T(AH^{-1}A^T)^{-1}AH^{-1}B-C)-H^{-1}B\n",
    "\\end{array}\n",
    "$$\n",
    "### L1 norm:\n",
    "\n",
    "\\begin{array}{lll}\n",
    "    y \\in & \\text{argmin}_u & \\frac{1}{2} \\|u - x\\|^2 \\\\\n",
    "    & \\text{subject to} & \\sum_i |x_i|  - r = 0 \\\\\n",
    "    & & \n",
    "\\end{array}\n",
    "\n",
    "### Ln norm:\n",
    "\n",
    "\n",
    "\\begin{array}{lll}\n",
    "    y \\in & \\text{argmin}_u & \\frac{1}{2} \\|u - x\\|^2 \\\\\n",
    "    & \\text{subject to} & \\max_i |x_i|  - r = 0 \\\\\n",
    "    & & \n",
    "\\end{array}\n",
    "\n",
    "After Calculation, it turns out, for L1 and Ln norm:\n",
    "\\begin{array}{lll}\n",
    "   B=0 \\\\\n",
    "   H= I\\\\\n",
    "   C=-1 \\\\\n",
    "   Dy(r) = \\frac {a^T} {\\| a\\|_2^2}\\\\ \n",
    "   a= D_y h(r,y)\n",
    "\\end{array}\n",
    "\n",
    "The only difference is they have different $a$: \n",
    "\n",
    "For L1 norm, $a=vec\\{indictor(i \\in I^*) sign(y_i)\\}$\n",
    "\n",
    "For Ln norm, $a=vec\\{(y_i)\\}$\n",
    "\n",
    "Below is the implmentation of $Dy(r)$, I adapted some previous code from DDN repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective \n",
    "def f(r,y,x):\n",
    "    return 0.5* np.dot(y-x,y-x)\n",
    "\n",
    "# constraint\n",
    "def h(r,y,norm):\n",
    "    if norm=='L1':\n",
    "       # print(np.linalg.norm(y, 1)- np.sum(np.abs(y)))\n",
    "        return np.sum(np.abs(y))-r\n",
    "    if norm=='Ln':\n",
    "        # print(np.max(np.abs(y))-np.linalg.norm(y, np.inf))\n",
    "        return np.max(np.abs(y)) - r\n",
    "    elif norm=='L2':\n",
    "        return np.dot(y,y) - r**2\n",
    "# forward solve\n",
    "def solve_opt(x,r,f,norm):\n",
    "    result = opt.minimize(lambda y: f(r, y ,x), np.ones(np.shape(x)[0]),constraints=[{'type':'eq', 'fun': lambda y: h(r,y,norm)}] )\n",
    "    return result.x\n",
    "\n",
    "# forward solve (L2 norm only)\n",
    "def solve_analyical(x,r):\n",
    "    return r / np.sqrt(np.dot(x, x)) * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient for L2, L1 and Ln. For L2 we write down the gradient with closed form for check. We write the gradient by autograd for check too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_closed_form_L2(r,x):\n",
    "    return 1 / np.sqrt(np.dot(x, x)) * x\n",
    "\n",
    "def gradient_L2(r,x):\n",
    "    y = solve_analyical(x,r)\n",
    "    # a = 2*y\n",
    "    # B = np.zeros(2)\n",
    "    # C = -2*r\n",
    "    # nu = np.sqrt(np.sum((y-x)**2)/(4*np.sum(y**2)))\n",
    "    # H =(1-2*nu) *np.eye(2)\n",
    "    return r*y/(np.sum(y*y))\n",
    "\n",
    "def gradient_L1(r,x):\n",
    "    y= solve_opt(x,r,f,'L1')\n",
    "    a = np.sign(y)\n",
    "    #nu= (y-x)[0]*a[0]\n",
    "    #B = np.zeros(2)- nu*np.zeros(2)\n",
    "    #C = -1.0\n",
    "    #H = np.eye(2)-nu*np.zeros(2)\n",
    "    return a/(a@a)\n",
    "\n",
    "def gradient_Ln(r,x):\n",
    "    y= solve_opt(x,r,f,'Ln')\n",
    "    print('y:',y)\n",
    "    y=np.round(y,4)\n",
    "    print('y:',y)\n",
    "    a = np.array([0 if np.abs(yi)<np.max(np.abs(y)) else np.sign(yi) for yi in y])\n",
    "    #idx= np.where(y==y[np.abs(y)>=np.max(np.abs(y))])\n",
    "    #nu=np.sign(y)[idx]* (y-x)[idx]\n",
    "    #B= np.zeros(2)- nu*np.zeros(2)\n",
    "    #C= -1.0\n",
    "    print('a',a)\n",
    "    #H = np.eye(2)-nu*np.zeros(2)\n",
    "    print(a/(a@a))\n",
    "    return a/(a@a)\n",
    "\n",
    "def gradient_by_auto_diff(r,x,norm):\n",
    "    fY = grad(f, 1)\n",
    "    hY = grad(h,1)\n",
    "    hR = grad(h,0)\n",
    "    frY = jacobian(fY, 0)\n",
    "    fYY = jacobian(fY, 1)\n",
    "    hYY = jacobian(hY, 1)\n",
    "    hrY= jacobian(hY, 0)\n",
    "    y= solve_opt(x,r,f,norm)\n",
    "    #y=solve_analyical(x,r)\n",
    "    # print(y-solve_analyical(x,r))\n",
    "    indx = np.nonzero(hY(r, y,norm))\n",
    "    if len(indx[0]) == 0:\n",
    "        nu= 0.0\n",
    "    nu = fY(r, y, x)[indx[0][0]] / hY(r, y, norm)[indx[0][0]]\n",
    "    H = fYY(r, y, x) - nu * hYY(r, y, norm)\n",
    "    a = hY(r, y, norm)\n",
    "    B = frY(r, y, x) - nu * hrY(r, y, norm)\n",
    "    C = hR(r, y, norm)\n",
    "    con = np.stack((a, B), axis=1)\n",
    "    try:\n",
    "        v = sci.linalg.solve(H, con, assume_a='pos')\n",
    "    except:\n",
    "         return np.full((2, 1), np.nan).squeeze()\n",
    "    #print(nu,fYY(r, y, x),hYY(r, y, norm))\n",
    "    return (np.outer(v[:, 0], (v[:, 0].dot(B) - C) / v[:, 0].dot(a)) - v[:, 1:1 + 1]).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random generate x and r, check error between the gradient computed by different form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [-1.2419  1.18   -0.7854 -0.7418]\n",
      "r: 0.6128\n",
      "error:\n",
      "L2 closed form and L2 analytical DDN:  1.6653345369377348e-16\n",
      "L2 analytical DDN and L2 autograd:  1.2798437478145352e-06\n",
      "L1 analytical DDN and L1 autograd:  0.0\n",
      "y: [-0.61279767  0.61279734 -0.61279827 -0.6128    ]\n",
      "y: [-0.6128  0.6128 -0.6128 -0.6128]\n",
      "a [-1.  1. -1. -1.]\n",
      "[-0.25  0.25 -0.25 -0.25]\n",
      "Ln analytical DDN and Ln autograd:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/students/u6361796/.conda/envs/myconda/lib/python3.7/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    }
   ],
   "source": [
    "x= np.array([-1.2419,  1.1800, -0.7854, -0.7418])\n",
    "#r= random.uniform(0.1, 10)\n",
    "r=np.array(0.6128)\n",
    "print('x:',x)\n",
    "print('r:',r)\n",
    "print(\"error:\")\n",
    "print(\"L2 closed form and L2 analytical DDN: \", abs(np.sum(gradient_L2(r,x)-gradient_closed_form_L2(r,x) )))\n",
    "print(\"L2 analytical DDN and L2 autograd: \", abs(np.sum(gradient_L2(r,x)-gradient_by_auto_diff(r,x,'L2') )))\n",
    "print(\"L1 analytical DDN and L1 autograd: \", abs(np.sum(gradient_L1(r,x)-gradient_by_auto_diff(r,x,'L1') )))\n",
    "print(\"Ln analytical DDN and Ln autograd: \", abs(np.sum(gradient_Ln(r,x)-gradient_by_auto_diff(r,x,'Ln') )))\n",
    "#node= L1Sphere()\n",
    "#obj,_= node.project(torch.as_tensor(x), torch.as_tensor(r))\n",
    "#print(\"L1 analytical DDN and Ln prtorch: \", node.gradient(torch.tensor([1]),obj,torch.tensor(x))[1]-np.sum(gradient_L1(r,x)))\n",
    "#node= LInfSphere()\n",
    "#obj,_= node.project(torch.as_tensor(x), torch.as_tensor(r))\n",
    "#print(\"Ln analytical DDN and Ln pytorch: \", node.gradient(torch.tensor([1]),obj,torch.tensor(x))[1]-np.sum(gradient_Ln(r,x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learnable parameter on a bi-level optimisation problem\n",
    "We can test the DDN with learnable parameter on bi-level optimisation problem. We use sum of squared error as the upper level loss function\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "    \\text{minimize}_x & \\frac{1}{2} \\|y - y^\\text{target}\\|^2 \\\\\n",
    "    \\text{subject to} & y \\in \\left\\{ \\begin{array}{ll}\n",
    "        \\text{argmin}_u & f(x, u)\\\\\n",
    "        \\text{subject to} & h(x, u) = 0\n",
    "        \\end{array} \\right\\}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We will use Simple Gradient and LFBGS mathod to backpropogate and learn the parameter.  I adapted two methods from previous tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbfgs(node, y_target, max_iters=1000,x_init=None, theta_init=None, verbose=True, train_x=False):\n",
    "    \"\"\"\n",
    "    Example of using scipy.optimize to solve the problem via L-BFGS.\n",
    "    \"\"\"\n",
    "    theta_start = theta_init if theta_init is not None else 1.0\n",
    "    x_start = (x_init.clone() if type(x_init)==torch.Tensor else x_init.copy()) if x_init is not None else 1.0\n",
    "    if train_x:\n",
    "        para= torch.cat((x_start,torch.tensor([theta_start]))) if type(x_start)==torch.tensor else np.concatenate((x_start, np.array([theta_start])), axis=0)\n",
    "    else:\n",
    "        para= theta_start\n",
    "    def J(para):\n",
    "        if train_x:\n",
    "            x= para[:-1]\n",
    "            theta=para[-1]\n",
    "        else:\n",
    "            x=x_init\n",
    "            theta=para\n",
    "        if type(node)==LearnableRobustAverageNew:\n",
    "            y, _ = node.solve(x, theta)\n",
    "            return 0.5 * np.sum(np.square(y - y_target))\n",
    "        else:\n",
    "            x=torch.tensor(x)\n",
    "            theta=torch.tensor(theta)\n",
    "            y, _ = node.project(x, theta)\n",
    "            return  0.5 * ((y - y_target)**2).sum()\n",
    "    def dJdtheta(para):\n",
    "        if train_x:\n",
    "            x= para[:-1]\n",
    "            theta=para[-1]\n",
    "        else:\n",
    "            x=x_init\n",
    "            theta=para\n",
    "        if type(node)==LearnableRobustAverageNew:\n",
    "            y, _ = node.solve(x, theta)\n",
    "            dx,dr= node.gradient(x, y, theta)\n",
    "            DJdx=np.dot(y - y_target,dx).reshape((node.dim_x,))\n",
    "            DJdr=(y - y_target)*dr\n",
    "            if train_x:\n",
    "                return np.concatenate((DJdx,DJdr),axis=0)\n",
    "            else:\n",
    "                return DJdr\n",
    "        else:\n",
    "            x=torch.tensor(x)\n",
    "            theta=torch.tensor(theta)\n",
    "            y, is_outside = node.project(x, theta)\n",
    "            DJdx, DJdtheta = node.gradient((y - y_target),x, y,is_outside)\n",
    "            if train_x:\n",
    "                return torch.cat((DJdx,torch.tensor([DJdtheta])))\n",
    "            else:\n",
    "                return torch.tensor([DJdtheta])\n",
    "    history = [J(para)]\n",
    "    thetas=[theta_start]\n",
    "    if type(node)==LearnableRobustAverageNew:\n",
    "        ys=[node.solve(x_start, theta_start)]\n",
    "    else:\n",
    "        ys=[node.project(x_start, theta_start)]\n",
    "    def callback(para):\n",
    "        if train_x:\n",
    "            x= para[:-1]\n",
    "            theta=para[-1]\n",
    "        else:\n",
    "            x=x_init\n",
    "            theta=para\n",
    "        thetas.append(theta)\n",
    "        history.append(J(para))\n",
    "        if type(node)==LearnableRobustAverageNew:\n",
    "            ys.append(node.solve(x, theta))\n",
    "        else:\n",
    "            x=torch.tensor(x)\n",
    "            theta=torch.tensor(theta)\n",
    "            ys.append(node.project(x, theta))\n",
    "    opts = {'maxiter': max_iters, 'disp': verbose}\n",
    "    result = opt.minimize(J, para, args=(), method='L-BFGS-B', jac=dJdtheta, options=opts, callback=callback)\n",
    "    if train_x:\n",
    "        x_final= result.x[:-1]\n",
    "        theta_final= result.x[-1]\n",
    "        if type(node)!=LearnableRobustAverageNew:\n",
    "            x_final=torch.tensor(x_final)\n",
    "            theta_final=torch.tensor([theta_final])\n",
    "    else:\n",
    "        x_final =x_init\n",
    "        theta_final= result.x\n",
    "    return theta_final, history,thetas,ys,x_final\n",
    "\n",
    "\n",
    "def simpleGradientDescent(node, y_target, step_size=1.0e-3, tol=1.0e-6, max_iters=10000,x_init = None, theta_init=None, verbose=False,train_x=False):\n",
    "    theta = theta_init if theta_init is not None else 0\n",
    "    if type(node)==LearnableRobustAverageNew:\n",
    "        x = x_init.copy()\n",
    "        J = lambda y : 0.5 * np.sum(np.square(y - y_target))\n",
    "    else:\n",
    "        x = x_init.clone()\n",
    "        J = lambda y : 0.5 * ((y - y_target)**2).sum()\n",
    "    dJdy = lambda y : y - y_target\n",
    "    history = []\n",
    "    thetas=[]\n",
    "    ys=[]\n",
    "    for i in range(max_iters):\n",
    "        # solve the lower-level problem and compute the upper-level objective\n",
    "        if type(node)==LearnableRobustAverageNew:\n",
    "            y, _ = node.solve(x,theta)\n",
    "        else:\n",
    "            y, is_outside = node.project(x,theta)\n",
    "        history.append(J(y))\n",
    "        if verbose: print(\"{:5d}: {}\".format(i, history[-1]))\n",
    "#         if (len(history) > 2) and (history[-2] - history[-1]) < tol:\n",
    "#             break\n",
    "        # compute the gradient of the upper-level objective with respect to x via the chain rule\n",
    "        if type(node)==LearnableRobustAverageNew:\n",
    "            dydx,dydtheta= node.gradient(x, y,theta)\n",
    "            dJdx = np.dot(dJdy(y), dydx)\n",
    "            dJdtheta = np.dot(dJdy(y), dydtheta)\n",
    "        else:\n",
    "            dJdx,dJdtheta = node.gradient(dJdy(y),x,y,is_outside)\n",
    "        # take a step in the negative gradient direction\n",
    "        theta -= step_size * dJdtheta\n",
    "        if train_x:\n",
    "            x -= step_size * dJdx\n",
    "        if type(node)==LearnableRobustAverageNew:\n",
    "            thetas.append(theta.copy())\n",
    "        else:\n",
    "            thetas.append(theta.clone())\n",
    "        ys.append(y)\n",
    "    return theta, history,thetas,ys,x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input x fix, learn parameters\n",
    "\n",
    "We first observe the converage of parameters($\\alpha$ and $r$) while setting the input x fixed: We generate target and init y with same x but different parameters. We generate all this data randomly.\n",
    "\n",
    "<span style=\"color:red\">Sometimes it is possible that $\\alpha,r$ run into negative, in this case the program will stop running as it is infeasible now, I am still trying to fix the bug in this situation.</span> \n",
    "### Set input x fix, learn parameters\n",
    "By set train_x= True, we can learnable both x and parameter at the same time. \n",
    "#### On robust pooling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6861177261579816\n",
      "0.5282906522634214\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1123)\n",
    "x_init=np.random.rand(50)\n",
    "idx= np.random.choice(50, 5)\n",
    "x_true=x_init.copy()\n",
    "x_init[idx] += x_init[idx]+1\n",
    "\n",
    "train_x=False\n",
    "# #train_x=True\n",
    "\n",
    "# if train_x:\n",
    "#     x_true=np.random.rand(5)\n",
    "#     x_true[np.random.randint(len(x_true))] += 100.0 * np.random.rand(1)\n",
    "# else:\n",
    "#     x_true=x_init.copy()\n",
    "    \n",
    "alpha_init=2.0\n",
    "\n",
    "\n",
    "p='huber'\n",
    "#p='Huber'\n",
    "#p='welsch'\n",
    "# np.random.seed(527)\n",
    "# N = 50\n",
    "# idx= np.random.choice(50, 20)\n",
    "# #print(y[idx])\n",
    "# x = np.random.rand(N)\n",
    "# y = np.random.rand(N)\n",
    "# y_mean=y.mean()\n",
    "# alpha_init=3.0\n",
    "print(x_init.mean())\n",
    "print(x_true.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67471344] 0.5282906522634214 (array([0.59235538]), None)\n"
     ]
    }
   ],
   "source": [
    "node = LearnableRobustAverageNew(50, penalty=p, alpha=alpha_init)\n",
    "y_target=x_true.mean()\n",
    "y_init,_=node.solve(x_init,alpha_init)\n",
    "print(y_init,y_target,node.solve(x_init,0.4))\n",
    "# alpha_gd1, history1,alphas1,ys1,x_final1 = lbfgs(node, y_target,max_iters=1000,x_init=x_init,theta_init=alpha_init, train_x=train_x)\n",
    "# print(alphas1)\n",
    "alpha_gd2, history2,alphas2,ys2,x_final2 = simpleGradientDescent(node, y_target,x_init=x_init, theta_init=alpha_init,step_size=0.5, train_x=train_x)\n",
    "#print(alphas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5092755])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(alphas2)\n",
    "# print('x_init:', x_init)\n",
    "# print('alpha init',alpha_init)\n",
    "# print('y init', y_init)\n",
    "# print(\"\")\n",
    "# print(\"x_true\",x_init)\n",
    "# print('alpha true',alpha_true)\n",
    "# print('y true',y_target)\n",
    "# print(\"\")\n",
    "# print('x_final lfbgs:', x_final1)\n",
    "# print('x_final simple gradient:',x_final2)\n",
    "# print(\"\")\n",
    "# print('alpha final lfbgs: ', alpha_gd1)\n",
    "# print('alpha final simple gradient ',alpha_gd2)\n",
    "# print(\"\")\n",
    "# print('y final lbfg:', node.solve(x_final1, alpha_gd1)[0])\n",
    "alphas2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p='huber'\n",
    "np.random.seed(527)\n",
    "N = 50\n",
    "idx= np.random.choice(50, 20)\n",
    "#print(y[idx])\n",
    "x = np.random.rand(N)\n",
    "y = np.random.rand(N)\n",
    "y[idx]=y[idx]*5\n",
    "y_mean=y.mean()\n",
    "alpha_init=3.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, array([4.])]\n",
      "[array([3.0000211]), array([3.0000422])]\n"
     ]
    }
   ],
   "source": [
    "node = LearnableRobustAverageNew(50, penalty=p, alpha=alpha_init)\n",
    "y_target=y_mean\n",
    "y_init,_=node.solve(y,alpha_init)\n",
    "alpha_gd1, history1,alphas1,ys1,x_final1 = lbfgs(node, y_target,max_iters=1000,x_init=y,theta_init=alpha_init, train_x=False)\n",
    "alpha_gd2, history2,alphas2,ys2,x_final2 = simpleGradientDescent(node, y_target,x_init=y, theta_init=alpha_init,step_size=0.5, train_x=False)\n",
    "print(alphas1)\n",
    "print(alphas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/students/u6361796/.conda/envs/myconda/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'alpha_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d7b7387e0c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemilogy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemilogy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemilogy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha_true\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iter.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bi-level optimization on sphere projection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-d7b7387e0c53>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemilogy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemilogy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemilogy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha_true\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iter.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bi-level optimization on sphere projection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alpha_true' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.semilogy(history1, lw=2)\n",
    "plt.semilogy(history2, lw=2)\n",
    "plt.xlabel(\"iter.\"); plt.ylabel(\"sum of squared error\")\n",
    "plt.title(\"Bi-level optimization on sphere projection\")\n",
    "plt.legend([\"LBFGS ({} iterations)\".format(len(history1)),\"GD ({} iterations)\".format(len(history2))])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(alphas1, lw=2)\n",
    "plt.semilogy(alphas2, lw=2)\n",
    "plt.semilogy([alpha_true for i in range(len(alphas2))], lw=2,linestyle='dashed')\n",
    "plt.xlabel(\"iter.\"); plt.ylabel(\"r\")\n",
    "plt.title(\"Bi-level optimization on sphere projection\")\n",
    "plt.legend([\"LBFGS ({} iterations)\".format(len(history1)),\"GD ({} iterations)\".format(len(history2)),'true r'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On ball projection:\n",
    "\n",
    "Similarly, We can do bi-level optimisation learning for ball projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node = L1Sphere()\n",
    "node = LInfSphere()\n",
    "# node = L1Ball()\n",
    "\n",
    "x_init = torch.as_tensor(np.random.rand(10))\n",
    "r_init=torch.as_tensor(random.uniform(15, 20))\n",
    "y_init,_ = node.project(x_init,r_init)\n",
    "\n",
    "if train_x:\n",
    "    x_true = torch.as_tensor(np.random.rand(10))\n",
    "else:\n",
    "    x_true = x_init.clone()\n",
    "r_true=torch.as_tensor(random.uniform(1, 5))\n",
    "y_target,_ = node.project(x_true,r_true)\n",
    "\n",
    "train_x=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_gd1, history1,rs1,ys1,x_final1 = lbfgs(node, y_target,max_iters=1000,x_init=x_init,theta_init=r_init,train_x=train_x)\n",
    "r_gd2, history2,rs2,ys2,x_final2 = simpleGradientDescent(node, y_target,max_iters=1000,x_init=x_init,theta_init=r_init,step_size=0.5,train_x=train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x init:', x_init)\n",
    "print('r init:',r_init)\n",
    "print('y init:',y_init)\n",
    "print(\"\")\n",
    "print('x true:',x_true)\n",
    "print('r true:',r_true)\n",
    "print('y true:',y_target)\n",
    "print()\n",
    "print('x final lbfg: ',x_final1)\n",
    "print('x final simple gradient: ',x_final2)\n",
    "print()\n",
    "print('r final lbfg: ',r_gd1)\n",
    "print('r final simple gradient: ',r_gd2)\n",
    "print()\n",
    "print('y final lbfg:',node.project(x_final1, r_gd1)[0])\n",
    "print('y final simple gradient:',node.project(x_final2, r_gd2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(history1, lw=2)\n",
    "plt.semilogy(history2, lw=2)\n",
    "plt.xlabel(\"iter.\"); plt.ylabel(\"sum of squared error\")\n",
    "plt.title(\"Bi-level optimization on sphere projection\")\n",
    "plt.legend([\"LBFGS ({} iterations)\".format(len(history1)),\"GD ({} iterations)\".format(len(history2))])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(rs1, lw=2)\n",
    "plt.semilogy(rs2, lw=2)\n",
    "plt.semilogy([r_true for i in range(len(rs2))], lw=2,linestyle='dashed')\n",
    "plt.xlabel(\"iter.\"); plt.ylabel(\"r\")\n",
    "plt.title(\"Bi-level optimization on sphere projection\")\n",
    "plt.legend([\"LBFGS ({} iterations)\".format(len(history1)),\"GD ({} iterations)\".format(len(history2)),'true r'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
